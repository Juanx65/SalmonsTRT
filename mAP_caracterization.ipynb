{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "C = 3 # number of channels of the input image\n",
    "H = 640 # heigh of the input image\n",
    "W = 640 # width of the input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mAP CARACTERIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('weights/yolov8lsalmons.pt', task='segment')\n",
    "metrics = model.val(data='datasets/salmons/salmons.yaml', task='segment', verbose=False,conf=0.4,device='cuda')\n",
    "print('base model box mAP50: ', metrics.box.map50)\n",
    "print('base model box mAP50-95: ', metrics.box.map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRT fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('weights/yolov11salmons_fp32.engine', task='segment')\n",
    "metrics = model.val(data='datasets/salmons/salmons.yaml', task='segment', verbose=False,conf=0.4,device='cuda')\n",
    "print('base model box mAP50: ', metrics.box.map50)\n",
    "print('base model box mAP50-95: ', metrics.box.map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRT fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('weights/yolov11salmons.engine', task='segment')\n",
    "metrics = model.val(data='datasets/salmons/salmons.yaml', task='segment', verbose=False,conf=0.4,device='cuda')\n",
    "print('base model box mAP50: ', metrics.box.map50)\n",
    "print('base model box mAP50-95: ', metrics.box.map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRT int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('weights/yolov11salmons_int8.engine', task='segment')\n",
    "metrics = model.val(data='datasets/salmons/salmons.yaml', task='segment', verbose=False,conf=0.4,device='cuda')\n",
    "print('base model box mAP50: ', metrics.box.map50)\n",
    "print('base model box mAP50-95: ', metrics.box.map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIXEL TO PIXEL CARACTERIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare output segmentations masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"datasets/salmons/images/val/Img3.jpeg\")\n",
    "image = cv2.resize(image, (H, W))\n",
    "cv2.imwrite(\"datasets/salmon_resized.png\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = YOLO('weights/yolov8lsalmons.pt', task='segment')\n",
    "trt_model =  YOLO('weights/yolov8lsalmons.engine', task='segment')\n",
    "results_base = base_model.predict(\"datasets/salmons/images/val/Img3.jpeg\",show_boxes=False,save=True, conf=0.4)\n",
    "results_trt = trt_model.predict(\"datasets/salmons/images/val/Img3.jpeg\", show_boxes=False,save=True, conf=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las máscaras de los resultados\n",
    "masks_base = results_base[0].masks.data.cpu()  # Máscaras del modelo base\n",
    "masks_trt = results_trt[0].masks.data.cpu()   # Máscaras del modelo optimizado\n",
    "\n",
    "# Verificar que las dimensiones sean iguales\n",
    "if masks_base.shape != masks_trt.shape:\n",
    "    print(masks_base.shape,\" != \",masks_trt.shape, \" :( \" )\n",
    "    print(\"Las máscaras tienen dimensiones diferentes y no pueden compararse directamente.\")\n",
    "else:\n",
    "    # Comparar igualdad exacta\n",
    "    are_equal = np.array_equal(masks_base, masks_trt)\n",
    "    print(f\"¿Las segmentaciones son exactamente iguales? {'Sí' if are_equal else 'No'}\")\n",
    "    \n",
    "    # Calcular el índice de Jaccard (IoU) promedio entre todas las máscaras\n",
    "    iou_scores = []\n",
    "    for mask_base, mask_trt in zip(masks_base, masks_trt):\n",
    "        intersection = np.logical_and(mask_base, mask_trt).sum()\n",
    "        union = np.logical_or(mask_base, mask_trt).sum()\n",
    "        iou = intersection / union if union != 0 else 0\n",
    "        iou_scores.append(iou)\n",
    "    \n",
    "    mean_iou = np.mean(iou_scores)\n",
    "    print(f\"Promedio del índice de Jaccard (IoU): {mean_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(image1, image2):\n",
    "    # Leer imágenes en escala de grises\n",
    "    img1 = cv2.imread(image1) # imagen del modelo base\n",
    "    img2 = cv2.imread(image2) # imagen del modelo optimizado\n",
    "\n",
    "    if img1.shape != img2.shape:\n",
    "        raise ValueError(\"Las imágenes deben tener el mismo tamaño y número de canales\")\n",
    "\n",
    "    # Convertir a escala de grises\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calcular la diferencia absoluta\n",
    "    diferencia = cv2.absdiff(gray1, gray2)\n",
    "\n",
    "    # Umbral para obtener las diferencias significativas\n",
    "    _, imagen_binaria = cv2.threshold(diferencia, 1, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Crear una máscara donde las diferencias sean no-cero\n",
    "    mask = cv2.merge([imagen_binaria, imagen_binaria, imagen_binaria])\n",
    "\n",
    "    # Crear una superposición roja\n",
    "    overlay = np.zeros_like(img1, dtype=np.uint8)\n",
    "    overlay[:, :, 2] = 255  # Canal rojo\n",
    "\n",
    "    # Aplicar la superposición roja donde haya diferencias\n",
    "    img1_con_diferencias = cv2.addWeighted(img1, 0.5, overlay, 0.5, 0.5)\n",
    "    img1_con_diferencias[mask == 0] = img1[mask == 0]\n",
    "\n",
    "    return img1_con_diferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacion_binaria = compare_images('outputs/segmentation/vanilla.jpg','outputs/segmentation/fp16.jpg')\n",
    "cv2.imwrite('outputs/segmentation/salmon_binario.jpg', comparacion_binaria)\n",
    "# Mostrar la imagen con matplotlib\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(cv2.cvtColor(comparacion_binaria, cv2.COLOR_BGR2RGB))  # Convertir de BGR a RGB para mostrar correctamente con matplotlib\n",
    "plt.axis('off')  # Ocultar ejes\n",
    "plt.title(\"Diferencias resaltadas en rojo\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
