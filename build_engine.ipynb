{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 17:19:03 - matplotlib - DEBUG - matplotlib data path: /home/juanhp/Documents/SalmonsTRT/salmons/lib/python3.10/site-packages/matplotlib/mpl-data\n",
      "2024-12-27 17:19:03 - matplotlib - DEBUG - CONFIGDIR=/home/juanhp/.config/matplotlib\n",
      "2024-12-27 17:19:03 - matplotlib - DEBUG - interactive is False\n",
      "2024-12-27 17:19:03 - matplotlib - DEBUG - platform is linux\n",
      "2024-12-27 17:19:03 - matplotlib - DEBUG - CACHEDIR=/home/juanhp/.cache/matplotlib\n",
      "2024-12-27 17:19:03 - matplotlib.font_manager - DEBUG - Using fontManager instance from /home/juanhp/.cache/matplotlib/fontlist-v390.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTES\n",
    "BATCH_SIZE = -1\n",
    "C = 3 # number of channels of the input image\n",
    "H = 224 # heigh of the input image\n",
    "W = 224 # width of the input image\n",
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX: Model conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      "YOLOv8l-seg summary (fused): 313 layers, 41,738,835 parameters, 0 gradients, 200.5 GFLOPs\n",
      "model stride:  32\n",
      "dynamic:  {'images': {0: 'batch', 2: 'height', 3: 'width'}, 'output0': {0: 'batch', 2: 'anchors'}, 'output1': {0: 'batch', 2: 'mask_height', 3: 'mask_width'}}\n",
      "fake input:  torch.Size([16, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juanhp/Documents/SalmonsTRT/salmons/lib/python3.10/site-packages/ultralytics/utils/tal.py:338: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for i, stride in enumerate(strides):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La conversi√≥n a ONNX se ha completado exitosamente. El modelo se ha guardado en: /home/juanhp/Documents/SalmonsTRT/weights/yolov11salmons.onnx\n"
     ]
    }
   ],
   "source": [
    "%run onnx_transform.py --weights weights/yolov11salmons.pt --input_shape $BATCH_SIZE $C $H $W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRT fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/27/2024-16:28:48] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[12/27/2024-16:28:48] [TRT] [W] input \"images\" with shape: (-1, 3, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:28:48] [TRT] [W] output \"output0\" with shape: (-1, 37, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:28:48] [TRT] [W] output \"output1\" with shape: (-1, 32, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:31:29] [TRT] [W] Build tensorrt engine finish.\n",
      "Save in /home/juanhp/Documents/SalmonsTRT/weights/yolov11salmons_fp32.engine\n"
     ]
    }
   ],
   "source": [
    "%run build_trt.py --weights weights/yolov11salmons.onnx  --fp32 --input_shape $BATCH_SIZE $C $H $W --engine_name yolov11salmons_fp32.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRT fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/27/2024-16:32:17] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[12/27/2024-16:32:17] [TRT] [W] input \"images\" with shape: (-1, 3, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:32:17] [TRT] [W] output \"output0\" with shape: (-1, 37, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:32:17] [TRT] [W] output \"output1\" with shape: (-1, 32, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:39:13] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "[12/27/2024-16:39:13] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "[12/27/2024-16:39:13] [TRT] [W] Check verbose logs for the list of affected weights.\n",
      "[12/27/2024-16:39:13] [TRT] [W] - 114 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "[12/27/2024-16:39:13] [TRT] [W] - 1 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n",
      "[12/27/2024-16:39:14] [TRT] [W] Build tensorrt engine finish.\n",
      "Save in /home/juanhp/Documents/SalmonsTRT/weights/yolov11salmons_fp16.engine\n"
     ]
    }
   ],
   "source": [
    "%run build_trt.py --weights weights/yolov11salmons.onnx  --fp16 --input_shape $BATCH_SIZE $C $H $W --engine_name yolov11salmons_fp16.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRT int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 17:19:18 - utils.engine - INFO - Collecting calibration files from: datasets/img_preprocess/\n",
      "2024-12-27 17:19:18 - utils.engine - INFO - Number of Calibration Files found: 256\n",
      "2024-12-27 17:19:19 - utils.engine - INFO - Using calibration cache to save time: outputs/cache/calibration.cache\n",
      "2024-12-27 17:19:19 - utils.engine - INFO - Using calibration cache to save time: outputs/cache/calibration.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/27/2024-17:19:18] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[12/27/2024-17:19:18] [TRT] [W] input \"images\" with shape: (-1, 3, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-17:19:18] [TRT] [W] output \"output0\" with shape: (-1, 37, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-17:19:18] [TRT] [W] output \"output1\" with shape: (-1, 32, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Squeeze_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Squeeze_1_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Squeeze_2_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 968) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 969) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 979) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 983) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 984) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 994) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_6_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_7_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1059) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1060) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1070) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1074) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1075) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1085) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_11_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_12_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1149) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1150) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1160) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1164) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1165) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1175) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_16_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_17_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/dfl/Softmax_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1343) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:32:13] [TRT] [W] Build tensorrt engine finish.\n",
      "Save in /home/juanhp/Documents/SalmonsTRT/weights/yolov11salmons_int8.engine\n"
     ]
    }
   ],
   "source": [
    "%run build_trt.py --weights weights/yolov11salmons.onnx  --int8 --input_shape $BATCH_SIZE $C $H $W --engine_name yolov11salmons_int8.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('weights/yolov11salmons.engine', task='segment')\n",
    "metrics = model.val(data='datasets/salmons/salmons.yaml', imgsz=224, task='segment', verbose=False,conf=0.4,device='cuda',batch=1)\n",
    "print('base model box mAP50: ', metrics.box.map50)\n",
    "print('base model box mAP50-95: ', metrics.box.map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
