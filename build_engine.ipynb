{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTES\n",
    "BATCH_SIZE = -1\n",
    "C = 3 # number of channels of the input image\n",
    "H = 640 # heigh of the input image\n",
    "W = 640 # width of the input image\n",
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX: Model conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      "YOLOv8l-seg summary (fused): 313 layers, 41,738,835 parameters, 0 gradients, 200.5 GFLOPs\n",
      "model stride:  32\n",
      "dynamic:  {'images': {0: 'batch', 2: 'height', 3: 'width'}, 'output0': {0: 'batch', 2: 'anchors'}, 'output1': {0: 'batch', 2: 'mask_height', 3: 'mask_width'}}\n",
      "fake input:  torch.Size([16, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juanhp/Documents/SalmonsTRT/salmons/lib/python3.10/site-packages/ultralytics/utils/tal.py:338: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for i, stride in enumerate(strides):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La conversi√≥n a ONNX se ha completado exitosamente. El modelo se ha guardado en: /home/juanhp/Documents/SalmonsTRT/weights/yolov11salmons.onnx\n"
     ]
    }
   ],
   "source": [
    "%run onnx_transform.py --weights weights/yolov11salmons.pt --input_shape $BATCH_SIZE $C $H $W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRT fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/27/2024-16:28:48] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[12/27/2024-16:28:48] [TRT] [W] input \"images\" with shape: (-1, 3, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:28:48] [TRT] [W] output \"output0\" with shape: (-1, 37, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:28:48] [TRT] [W] output \"output1\" with shape: (-1, 32, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:31:29] [TRT] [W] Build tensorrt engine finish.\n",
      "Save in /home/juanhp/Documents/SalmonsTRT/weights/yolov11salmons_fp32.engine\n"
     ]
    }
   ],
   "source": [
    "%run build_trt.py --weights weights/yolov11salmons.onnx  --fp32 --input_shape $BATCH_SIZE $C $H $W --engine_name yolov11salmons_fp32.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRT fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/27/2024-16:32:17] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[12/27/2024-16:32:17] [TRT] [W] input \"images\" with shape: (-1, 3, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:32:17] [TRT] [W] output \"output0\" with shape: (-1, 37, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:32:17] [TRT] [W] output \"output1\" with shape: (-1, 32, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-16:39:13] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "[12/27/2024-16:39:13] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "[12/27/2024-16:39:13] [TRT] [W] Check verbose logs for the list of affected weights.\n",
      "[12/27/2024-16:39:13] [TRT] [W] - 114 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "[12/27/2024-16:39:13] [TRT] [W] - 1 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n",
      "[12/27/2024-16:39:14] [TRT] [W] Build tensorrt engine finish.\n",
      "Save in /home/juanhp/Documents/SalmonsTRT/weights/yolov11salmons_fp16.engine\n"
     ]
    }
   ],
   "source": [
    "%run build_trt.py --weights weights/yolov11salmons.onnx  --fp16 --input_shape $BATCH_SIZE $C $H $W --engine_name yolov11salmons_fp16.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRT int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 17:19:18 - utils.engine - INFO - Collecting calibration files from: datasets/img_preprocess/\n",
      "2024-12-27 17:19:18 - utils.engine - INFO - Number of Calibration Files found: 256\n",
      "2024-12-27 17:19:19 - utils.engine - INFO - Using calibration cache to save time: outputs/cache/calibration.cache\n",
      "2024-12-27 17:19:19 - utils.engine - INFO - Using calibration cache to save time: outputs/cache/calibration.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/27/2024-17:19:18] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[12/27/2024-17:19:18] [TRT] [W] input \"images\" with shape: (-1, 3, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-17:19:18] [TRT] [W] output \"output0\" with shape: (-1, 37, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-17:19:18] [TRT] [W] output \"output1\" with shape: (-1, 32, -1, -1) dtype: DataType.FLOAT\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Squeeze_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Squeeze_1_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Squeeze_2_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 968) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 969) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 979) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 983) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 984) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 994) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_6_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_7_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1059) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1060) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1070) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1074) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1075) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1085) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_11_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_12_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1149) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1150) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1160) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1164) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1165) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1175) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_16_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/Reshape_17_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor /model.22/dfl/Softmax_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:19:19] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1343) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[12/27/2024-17:32:13] [TRT] [W] Build tensorrt engine finish.\n",
      "Save in /home/juanhp/Documents/SalmonsTRT/weights/yolov11salmons_int8.engine\n"
     ]
    }
   ],
   "source": [
    "%run build_trt.py --weights weights/yolov11salmons.onnx  --int8 --input_shape $BATCH_SIZE $C $H $W --engine_name yolov11salmons_int8.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.55 üöÄ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 11937MiB)\n",
      "Loading weights/yolov8lsalmons_fp16_own.engine for TensorRT inference...\n",
      "[01/03/2025-14:33:01] [TRT] [I] Loaded engine size: 90 MiB\n",
      "[01/03/2025-14:33:01] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +87, now: CPU 0, GPU 87 (MiB)\n",
      "[01/03/2025-14:33:01] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +6500, now: CPU 0, GPU 6587 (MiB)\n",
      "WARNING ‚ö†Ô∏è Metadata not found for 'model=weights/yolov8lsalmons_fp16_own.engine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/juan/Documents/SalmonsTRT/datasets/salmons/labels/val.cache... 52 images, 34 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86/86 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/03/2025-14:33:03] [TRT] [E] 1: [genericReformat.cuh::copyVectorizedRunKernel::1579] Error Code 1: Cuda Runtime (an illegal memory access was encountered)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/juan/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n    data = pin_memory(data, device)\n  File \"/home/juan/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n  File \"/home/juan/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n  File \"/home/juan/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n    return data.pin_memory(device)\nRuntimeError: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights/yolov8lsalmons_fp16_own.engine\u001b[39m\u001b[38;5;124m'\u001b[39m, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasets/salmons/salmons.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msegment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase model box mAP50: \u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmap50)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase model box mAP50-95: \u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmap)\n",
      "File \u001b[0;32m~/Documents/SalmonsTRT/env/lib/python3.10/site-packages/ultralytics/engine/model.py:639\u001b[0m, in \u001b[0;36mModel.val\u001b[0;34m(self, validator, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m    638\u001b[0m validator \u001b[38;5;241m=\u001b[39m (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidator\u001b[39m\u001b[38;5;124m\"\u001b[39m))(args\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[0;32m--> 639\u001b[0m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m validator\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SalmonsTRT/env/lib/python3.10/site-packages/ultralytics/engine/validator.py:171\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_metrics(de_parallel(model))\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjdict \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# empty before each val\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(bar):\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_val_batch_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_i \u001b[38;5;241m=\u001b[39m batch_i\n",
      "File \u001b[0;32m~/Documents/SalmonsTRT/env/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SalmonsTRT/env/lib/python3.10/site-packages/ultralytics/data/build.py:48\u001b[0m, in \u001b[0;36mInfiniteDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a sampler that repeats indefinitely.\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/_utils.py:705\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/juan/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n    data = pin_memory(data, device)\n  File \"/home/juan/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n  File \"/home/juan/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n  File \"/home/juan/Documents/SalmonsTRT/env/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n    return data.pin_memory(device)\nRuntimeError: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('weights/yolov8lsalmons_fp16_own.engine', task='segment')\n",
    "metrics = model.val(data='datasets/salmons/salmons.yaml', task='segment', verbose=False,conf=0.4,device='cuda')\n",
    "print('base model box mAP50: ', metrics.box.map50)\n",
    "print('base model box mAP50-95: ', metrics.box.map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
